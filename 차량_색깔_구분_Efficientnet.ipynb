{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOSQCgJ1mxmXyJxS8k+JOth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ru2zi/CP2_NEXTLAB/blob/main/%EC%B0%A8%EB%9F%89_%EC%83%89%EA%B9%94_%EA%B5%AC%EB%B6%84_Efficientnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델"
      ],
      "metadata": {
        "id": "keEsVULzFJD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwmfcajkDS1B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import functional\n",
        "from torch import Tensor, nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.sigmoid(x)\n",
        "\n",
        "\n",
        "# make channels to 1x1\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, in_channels, r=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.excitation = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels*r),\n",
        "            Swish(),\n",
        "            nn.Linear(in_channels*r, in_channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze(x)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.excitation(x)\n",
        "        x = x.view(x.size(0), x.size(1),1,1)\n",
        "        return x\n",
        "\n",
        "## mbconv -> bottleneck  1x1 -> nxn -> 1x1\n",
        "class MBConv(nn.Module):\n",
        "    expand = 6\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
        "        super().__init__()\n",
        "        # first MBConv is not using stochastic depth\n",
        "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
        "\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels * MBConv.expand, 1, stride=stride, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
        "            Swish(),\n",
        "            nn.Conv2d(in_channels * MBConv.expand, in_channels * MBConv.expand, kernel_size=kernel_size,\n",
        "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*MBConv.expand),\n",
        "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
        "            Swish()\n",
        "        )\n",
        "\n",
        "        self.se = SEBlock(in_channels * MBConv.expand, se_scale)\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(in_channels*MBConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
        "        )\n",
        "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # stochastic depth\n",
        "        if self.training:\n",
        "            if not torch.bernoulli(self.p):\n",
        "                return x\n",
        "\n",
        "        x_shortcut = x\n",
        "        x_residual = self.residual(x)\n",
        "        x_se = self.se(x_residual)\n",
        "\n",
        "        x = x_se * x_residual\n",
        "        x = self.project(x)\n",
        "\n",
        "        if self.shortcut:\n",
        "            x= x_shortcut + x\n",
        "\n",
        "        return x\n",
        "\n",
        "class SepConv(nn.Module):\n",
        "    expand = 1\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
        "        super().__init__()\n",
        "        # first SepConv is not using stochastic depth\n",
        "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
        "\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv2d(in_channels * SepConv.expand, in_channels * SepConv.expand, kernel_size=kernel_size,\n",
        "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*SepConv.expand),\n",
        "            nn.BatchNorm2d(in_channels * SepConv.expand, momentum=0.99, eps=1e-3),\n",
        "            Swish()\n",
        "        )\n",
        "\n",
        "        self.se = SEBlock(in_channels * SepConv.expand, se_scale)\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(in_channels*SepConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
        "        )\n",
        "\n",
        "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # stochastic depth\n",
        "        if self.training:\n",
        "            if not torch.bernoulli(self.p):\n",
        "                return x\n",
        "\n",
        "        x_shortcut = x\n",
        "        x_residual = self.residual(x)\n",
        "        x_se = self.se(x_residual)\n",
        "\n",
        "        x = x_se * x_residual\n",
        "        x = self.project(x)\n",
        "\n",
        "        if self.shortcut:\n",
        "            x= x_shortcut + x\n",
        "\n",
        "        return x\n",
        "\n",
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes=10, width_coef=1., depth_coef=1., scale=1., dropout=0.2, se_scale=4, stochastic_depth=False, p=0.5):\n",
        "        super().__init__()\n",
        "        channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
        "        repeats = [1, 2, 2, 3, 3, 4, 1]\n",
        "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
        "        kernel_size = [3, 3, 5, 3, 5, 5, 3]\n",
        "        depth = depth_coef\n",
        "        width = width_coef\n",
        "\n",
        "        channels = [int(x*width) for x in channels]\n",
        "        repeats = [int(x*depth) for x in repeats]\n",
        "\n",
        "        # stochastic depth\n",
        "        if stochastic_depth:\n",
        "            self.p = p\n",
        "            self.step = (1 - 0.5) / (sum(repeats) - 1)\n",
        "        else:\n",
        "            self.p = 1\n",
        "            self.step = 0\n",
        "\n",
        "\n",
        "        # efficient net\n",
        "        self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)\n",
        "\n",
        "        self.stage1 = nn.Sequential(\n",
        "            nn.Conv2d(3, channels[0],3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(channels[0], momentum=0.99, eps=1e-3)\n",
        "        )\n",
        "\n",
        "        self.stage2 = self._make_Block(SepConv, repeats[0], channels[0], channels[1], kernel_size[0], strides[0], se_scale)\n",
        "\n",
        "        self.stage3 = self._make_Block(MBConv, repeats[1], channels[1], channels[2], kernel_size[1], strides[1], se_scale)\n",
        "\n",
        "        self.stage4 = self._make_Block(MBConv, repeats[2], channels[2], channels[3], kernel_size[2], strides[2], se_scale)\n",
        "\n",
        "        self.stage5 = self._make_Block(MBConv, repeats[3], channels[3], channels[4], kernel_size[3], strides[3], se_scale)\n",
        "\n",
        "        self.stage6 = self._make_Block(MBConv, repeats[4], channels[4], channels[5], kernel_size[4], strides[4], se_scale)\n",
        "\n",
        "        self.stage7 = self._make_Block(MBConv, repeats[5], channels[5], channels[6], kernel_size[5], strides[5], se_scale)\n",
        "\n",
        "        self.stage8 = self._make_Block(MBConv, repeats[6], channels[6], channels[7], kernel_size[6], strides[6], se_scale)\n",
        "\n",
        "        self.stage9 = nn.Sequential(\n",
        "            nn.Conv2d(channels[7], channels[8], 1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(channels[8], momentum=0.99, eps=1e-3),\n",
        "            Swish()\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.linear = nn.Linear(channels[8], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.upsample(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.stage5(x)\n",
        "        x = self.stage6(x)\n",
        "        x = self.stage7(x)\n",
        "        x = self.stage8(x)\n",
        "        x = self.stage9(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_Block(self, block, repeats, in_channels, out_channels, kernel_size, stride, se_scale):\n",
        "        strides = [stride] + [1] * (repeats - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(in_channels, out_channels, kernel_size, stride, se_scale, self.p))\n",
        "            in_channels = out_channels\n",
        "            self.p -= self.step\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def efficientnet_b0(num_classes):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.1, depth_coef=1.2, scale=1.15,dropout=0.2, se_scale=4)"
      ],
      "metadata": {
        "id": "z0jJlRriDU3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_effi = efficientnet_b0(4)"
      ],
      "metadata": {
        "id": "AI_WVFWKDX_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "XVf_jB1CDZ9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "L6zwwaW4DbG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary(model_effi))"
      ],
      "metadata": {
        "id": "lptAIRETDc6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이미지"
      ],
      "metadata": {
        "id": "xBOuZ_8VFN6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "oTA_0XWQDepj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torch.utils.data as data\n",
        "from torchvision import transforms\n",
        "\n",
        "### ImageFolder 작성\n",
        "train_imgs = ImageFolder(\"/content/drive/MyDrive/car_color/class_output_resize/train\",\n",
        "                         transform=transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                       transforms.ToTensor()]))\n",
        "\n",
        "val_imgs = ImageFolder(\"/content/drive/MyDrive/car_color/class_output_resize/val\",\n",
        "                        transform=transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                      transforms.ToTensor()]))\n",
        "\n",
        "test_imgs = ImageFolder(\"/content/drive/MyDrive/car_color/class_output_resize/test\",\n",
        "                        transform=transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                      transforms.ToTensor()]))\n",
        "batch_size = 64\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = data.DataLoader(train_imgs, batch_size, shuffle=True)\n",
        "dataloaders['valid'] = data.DataLoader(val_imgs, batch_size, shuffle=True)\n",
        "dataloaders['test'] = data.DataLoader(test_imgs, batch_size, shuffle=True)\n",
        "batch_num['train'], batch_num['valid'], batch_num['test'] = len(dataloaders['train']), len(dataloaders['valid']), len(dataloaders['test'])\n",
        "\n",
        "print('batch_size : %d,  tvt : %d / %d / %d' % (batch_size, batch_num['train'], batch_num['valid'], batch_num['test']))"
      ],
      "metadata": {
        "id": "KvN9In7zDfqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs.class_to_idx"
      ],
      "metadata": {
        "id": "Meqo4knUDhi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_effi.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "Vuyw8CIFDjH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "metadata": {
        "id": "ZJd1CAEZDkn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = [p for p in glob.glob('/content/drive/MyDrive/car_color/class_output_resize/train/**/*.jpg', recursive=True)if os.path.isfile(p)]\n",
        "test_dataset = [p for p in glob.glob('/content/drive/MyDrive/car_color/class_output_resize/test/**/*.jpg', recursive=True)if os.path.isfile(p)]\n"
      ],
      "metadata": {
        "id": "Ej5vo5PLDlpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "tA8WjnPuFRGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "84UGUg5cFTYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy"
      ],
      "metadata": {
        "id": "0EkoMZ1VDnE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "            print('{} Loss: {:.2f} Acc: {:.1f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            #best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc"
      ],
      "metadata": {
        "id": "aSmUMBNDDoMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model_effi = model_effi.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model_effi.parameters(),\n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)"
      ],
      "metadata": {
        "id": "Mk-bF8EUDp9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc = train_model(model_effi, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10)"
      ],
      "metadata": {
        "id": "EtGZNUyuDrKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_effi.load_state_dict(torch.load('/content/drive/MyDrive/car_color/president_model.pt'))\n",
        "model_effi.eval()"
      ],
      "metadata": {
        "id": "GD-2nAnEDsil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결과 그래프"
      ],
      "metadata": {
        "id": "CP2eXfLUFez_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## acc 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc)\n",
        "ax1.plot(valid_acc)\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "plot.legend(['Train', 'val'], loc='upper left')\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cTShMHw0DuCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Loss 결과 그래프 그리기\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_loss)\n",
        "ax1.plot(valid_loss)\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "plot.legend(['Train', 'val'], loc='upper left')\n",
        "ax1.set_ylabel('loss', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W3ve16-kDwKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = {\n",
        "\n",
        "    \"0\": \"bk\",\n",
        "    \"1\": \"bl\",\n",
        "    \"2\": \"gr\",\n",
        "    \"3\": \"wh\"\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "OYk-lBRkDxak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "HjNh-3QRFtwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_and_visualize_model(model, phase = 'test'):\n",
        "\n",
        "    model_effi.eval()\n",
        "\n",
        "    running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss    += loss.item() * inputs.size(0)\n",
        "            running_corrects+= torch.sum(preds == labels.data)\n",
        "            num_cnt += inputs.size(0)\n",
        "\n",
        "\n",
        "\n",
        "        test_loss = running_loss / num_cnt\n",
        "        test_acc  = running_corrects.double() / num_cnt\n",
        "        print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_and_visualize_model(model_effi, phase = 'test')"
      ],
      "metadata": {
        "id": "HU4ITjiIDy2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model_effi(inputs)\n",
        "        _, preds = torch.max(outputs, 1)"
      ],
      "metadata": {
        "id": "SFtCJTABDz9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test sample 시각화"
      ],
      "metadata": {
        "id": "nBO6ZB7TFygk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plt.subplot(1, 1,1)\n",
        "ax.axis('off')\n",
        "ax.set_title('%s : %s -> %s'%(\n",
        "    'True' if class_names[str(labels[12].cpu().numpy())]==class_names[str(preds[12].cpu().numpy())] else 'False',\n",
        "    class_names[str(labels[12].cpu().numpy())], class_names[str(preds[12].cpu().numpy())]))\n",
        "plt.imshow(np.swapaxes(inputs.cpu().data[12], 0, 2))\n"
      ],
      "metadata": {
        "id": "7jy5uCNaD1Gd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}